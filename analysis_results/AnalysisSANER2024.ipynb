{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_experiment, get_experiment_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hours=\"5\"\n",
    "simulations=\"5\"\n",
    "reqs=\"50\"\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), f'results', f'{hours}hours_incremental_data')\n",
    "print(os.path.isdir(base_dir))\n",
    "\n",
    "MIN_REQ = '50'\n",
    "MAX_REQ = '50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals, all_rec_individuals, all_results, all_time_df = load_experiment(base_dir=f'{base_dir}/results', objectives_labels=['delivery_rate', 'utilization_rate', 'num_risks'], variables_labels=['robot_0_start', 'robot_0_end', 'robot_1_start', 'robot_1_end', 'robot_2_start', 'robot_2_end', 'robot_3_start', 'robot_3_end', 'robot_4_start', 'robot_4_end', 'robot_5_start', 'robot_5_end', 'robot_6_start', 'robot_6_end', 'robot_7_start', 'robot_7_end', 'robot_8_start', 'robot_8_end', 'robot_9_start', 'robot_9_end', 'robot_speed_kmh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals['total_virtual_time'] = all_individuals['simulation_duration'] * all_individuals['simulations']\n",
    "all_rec_individuals['total_virtual_time'] = all_rec_individuals['simulation_duration'] * all_rec_individuals['simulations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the results that have the same number of requests (i.e., they are solutions to the same problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[(all_results.min_req==MIN_REQ) & (all_results.max_req==MAX_REQ)]\n",
    "all_individuals = all_individuals[(all_individuals.min_req==MIN_REQ) & (all_individuals.max_req==MAX_REQ)]\n",
    "all_rec_individuals = all_rec_individuals[(all_rec_individuals.min_req==MIN_REQ) & (all_rec_individuals.max_req==MAX_REQ)]\n",
    "all_time_df = all_time_df[(all_time_df.min_req==MIN_REQ) & (all_time_df.max_req==MAX_REQ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[(all_results.num_risks != 100000.00)]\n",
    "all_individuals = all_individuals[(all_individuals.num_risks != 100000.00)]\n",
    "all_rec_individuals = all_rec_individuals[(all_rec_individuals.num_risks != 100000.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals.to_csv(os.path.join(base_dir, f\"all_individuals.csv\"), index=False)\n",
    "all_results.to_csv(os.path.join(base_dir, f\"all_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jmetal.core.solution import Solution\n",
    "from jmetal.util.solution import get_non_dominated_solutions\n",
    "\n",
    "def get_non_dom_from_numpy(solutions):\n",
    "    real_solutions = []\n",
    "    for row in solutions:\n",
    "        x = row[3:]\n",
    "        y = row[:3]\n",
    "        solution = Solution(2, 3, 0)\n",
    "        solution.objectives = list(y)\n",
    "        real_solutions.append(solution)\n",
    "    non_dominated_solutions = get_non_dominated_solutions(real_solutions)\n",
    "    non_dominated_solutions = np.array([np.array(sol.objectives) for sol in non_dominated_solutions])\n",
    "    real_row = []\n",
    "    for non_dominated_solution in non_dominated_solutions:\n",
    "        row = np.where((non_dominated_solution==solutions[:,:3]).all(axis=1))\n",
    "        row = np.unique(row)\n",
    "        if row.shape[0] != 0:\n",
    "            real_row.append(row[0])\n",
    "    \n",
    "    return solutions[real_row]\n",
    "\n",
    "def get_solutions_as_numpy_array(exp_df):\n",
    "    return np.array([exp_df['delivery_rate'] * -1.0, exp_df['utilization_rate'] * -1.0, exp_df['num_risks'], exp_df['robot_0_start'], exp_df['robot_0_end'],\n",
    "                     exp_df['robot_1_start'], exp_df['robot_1_end'], exp_df['robot_2_start'], exp_df['robot_2_end'], exp_df['robot_3_start'], exp_df['robot_3_end'], \n",
    "                     exp_df['robot_4_start'], exp_df['robot_4_end'], exp_df['robot_5_start'], exp_df['robot_5_end'], exp_df['robot_6_start'], exp_df['robot_6_end'],\n",
    "                     exp_df['robot_7_start'], exp_df['robot_7_end'], exp_df['robot_8_start'], exp_df['robot_8_end'], exp_df['robot_9_start'], exp_df['robot_9_end'],\n",
    "                     exp_df['robot_speed_kmh']]).transpose()\n",
    "\n",
    "def get_need_PF(df):\n",
    "    list_row = []\n",
    "    count = 0\n",
    "    for index, (problem, approach, run) in df[['problem', 'approach', 'run']].drop_duplicates().iterrows():\n",
    "        row = {'problem': problem, 'simulator': approach, 'run': run} \n",
    "        exp_df = get_experiment_run(df=df, problem=problem, approach=approach, run=run)\n",
    "        solutions = get_solutions_as_numpy_array(exp_df)\n",
    "        non_dominated_solutions = get_non_dom_from_numpy(solutions)\n",
    "        for i in range(non_dominated_solutions.shape[0]):\n",
    "                list_row.append(row)\n",
    "        if count==0:\n",
    "            data = non_dominated_solutions\n",
    "        else:\n",
    "            data = np.concatenate((data,non_dominated_solutions))\n",
    "        count += 1\n",
    "    return data, list_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get need reeval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = ['17', '34', '51', '68']\n",
    "count = 0\n",
    "for idx, generation in enumerate(generations):\n",
    "    M = [i for i in range(1, int(generation))]\n",
    "    for using_M in M:\n",
    "        individuals = all_individuals[(all_individuals['generations']==generation) & (all_individuals['generation']<=using_M) & (all_individuals['approach'] == 'incremental-data_lab28_special_utilization_model12.pth')]\n",
    "        if count == 0:\n",
    "            data, df_row = get_need_PF(df=individuals)\n",
    "        else:\n",
    "            non_dominated_solutions, list_row = get_need_PF(df=individuals)\n",
    "            data = np.concatenate((data,non_dominated_solutions)) \n",
    "            df_row += list_row\n",
    "        count += 1\n",
    "for idx, generation in enumerate(generations):\n",
    "    M = [i for i in range(1, int(generation))]\n",
    "    for using_M in M:\n",
    "        individuals = all_individuals[(all_individuals['generations']==generation) & (all_individuals['generation']==using_M) & (all_individuals['approach'] == 'incremental-data_lab28_special_utilization_model12.pth')]\n",
    "        non_dominated_solutions, list_row = get_need_PF(df=individuals)\n",
    "        data = np.concatenate((data,non_dominated_solutions)) \n",
    "        df_row += list_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, indices = np.unique(data, axis=0, return_index=True)\n",
    "df_row = pd.DataFrame(df_row)\n",
    "data_df = pd.DataFrame(data, columns=['delivery_rate', 'utilization_rate', 'num_risk', 'robot_0_start', 'robot_0_end', 'robot_1_start', 'robot_1_end', 'robot_2_start', 'robot_2_end',\n",
    "                                      'robot_3_start', 'robot_3_end', 'robot_4_start', 'robot_4_end', 'robot_5_start', 'robot_5_end',\n",
    "                                      'robot_6_start', 'robot_6_end', 'robot_7_start', 'robot_7_end', 'robot_8_start', 'robot_8_end',\n",
    "                                      'robot_9_start', 'robot_9_end', 'speed_kmh'])\n",
    "data_df = pd.concat((data_df, df_row), axis=1)\n",
    "data_df = data_df.iloc[indices]\n",
    "data_df.to_csv(os.path.join(base_dir, \"need_reeval.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jmetal.core.quality_indicator import InvertedGenerationalDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the reference point and the reference point based on all data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference front based on the best individual point \n",
    "reference_front_orig = [[all_individuals['delivery_rate'].max() * -1.0, all_individuals['utilization_rate'].max() * -1.0,  all_individuals['num_risks'].min()]]\n",
    "reference_front_rec = [[all_rec_individuals['delivery_rate'].max() * -1.0, all_rec_individuals['utilization_rate'].max() * -1.0,  all_rec_individuals['num_risks'].min()]]\n",
    "print(\"reference_front_orig: \" + str(reference_front_orig) + \"  reference_front_rec: \" + str(reference_front_rec))\n",
    "reference_front = reference_front_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference front based on all non dominated solutions\n",
    "solutions_orig = get_solutions_as_numpy_array(all_individuals)\n",
    "reference_front_orig = get_non_dom_from_numpy(solutions_orig)\n",
    "solutions_rec = get_solutions_as_numpy_array(all_rec_individuals)\n",
    "reference_front_rec = get_non_dom_from_numpy(solutions_rec)\n",
    "print(\"reference_front_orig.shape: \" + str(reference_front_orig.shape) + \"  reference_front_rec.shape: \" + str(reference_front_rec.shape))\n",
    "reference_front = reference_front_rec[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"used_reference_front.npy\", reference_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_indicators = [InvertedGenerationalDistance(reference_front)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT = pd.read_csv(os.path.join(base_dir,\"look_up_table_var_robot.csv\"))\n",
    "\n",
    "def reeval(robots_working_period, speed):\n",
    "    \n",
    "    used_row = LUT\n",
    "    for idx in range(robots_working_period.shape[0]//2):\n",
    "        used_row = used_row[used_row[f'robot_{idx}_start'] == robots_working_period[2*idx]]\n",
    "        used_row = used_row[used_row[f'robot_{idx}_end'] == robots_working_period[2*idx+1]]\n",
    "    used_row = used_row[used_row['robot_speed_kmh'] == speed].drop_duplicates()\n",
    "    \n",
    "    return used_row['num_delivery_rate'].item() * -1.0, used_row['utilization_rate'].item() * -1.0, used_row['num_risk'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the quality indicators on all the runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_indicators(df, quality_indicator, using_H, using_M):\n",
    "    data = []\n",
    "    for index, (problem, approach, run) in df[['problem', 'approach', 'run']].drop_duplicates().iterrows():\n",
    "        row = {'problem': problem, 'approach': f'{approach}_H_{using_H}_M_{using_M}', 'run': run} \n",
    "        for quality_indicator in quality_indicators:\n",
    "            exp_df = get_experiment_run(df=df, problem=problem, approach=approach, run=run)\n",
    "            solutions = get_solutions_as_numpy_array(exp_df)\n",
    "            non_dominated_solutions = get_non_dom_from_numpy(solutions)\n",
    "            if approach != 'standard':\n",
    "                reeval_front = np.empty((non_dominated_solutions.shape[0],3))\n",
    "                for i, solution in enumerate(non_dominated_solutions):\n",
    "                    robots_working_period = solution[3:23]\n",
    "                    robot_speed_kmh = solution[23]\n",
    "                    reeval_front[i] = reeval(robots_working_period,robot_speed_kmh)\n",
    "                reeval_front = get_non_dom_from_numpy(reeval_front)\n",
    "                row[quality_indicator.get_short_name()] =  quality_indicator.compute(reeval_front[:,:3])\n",
    "            else:\n",
    "                row[quality_indicator.get_short_name()] =  quality_indicator.compute(non_dominated_solutions[:,:3])\n",
    "            # row[quality_indicator.get_short_name()] =  quality_indicator.compute(non_dominated_solutions[:,:3])\n",
    "        data.append(row)\n",
    "    qi_df = pd.DataFrame(data)\n",
    "    return qi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = ['17', '34', '51', '68']\n",
    "H = [1,2,3,4]\n",
    "M = [i for i in range(1,18)]\n",
    "individuals = all_individuals[(all_individuals['approach'] == 'standard')]\n",
    "quality_indicators_df = compute_quality_indicators(df=individuals, quality_indicator=quality_indicators, using_H=0, using_M=0)\n",
    "data = quality_indicators_df\n",
    "\n",
    "for idx, generation in enumerate(generations):\n",
    "    M = [i for i in range(1, int(generation))]\n",
    "    using_H = H[idx]\n",
    "    for using_M in M:\n",
    "        print(f'now each_gen using_generationH : {generation}, using_M: {using_M}')\n",
    "        individuals = all_individuals[(all_individuals['generations']==generation) & (all_individuals['generation']==using_M) & (all_individuals['approach'] == 'incremental-data_lab28_special_utilization_model12.pth')]\n",
    "        quality_indicators_df = compute_quality_indicators(df=individuals, quality_indicator=quality_indicators, using_H=using_H, using_M=using_M)\n",
    "        data = pd.concat((data, quality_indicators_df))\n",
    "\n",
    "quality_indicators_df = data\n",
    "quality_indicators_df.to_csv(os.path.join(base_dir, 're_eval_each_gen_quality_indicators.csv'), index=False)\n",
    "quality_indicators_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generations = ['17', '34', '51', '68']\n",
    "H = [1,2,3,4]\n",
    "M = [i for i in range(1,18)]\n",
    "individuals = all_individuals[(all_individuals['approach'] == 'standard')]\n",
    "quality_indicators_df = compute_quality_indicators(df=individuals, quality_indicator=quality_indicators, using_H=0, using_M=0)\n",
    "data = quality_indicators_df\n",
    "\n",
    "for idx, generation in enumerate(generations):\n",
    "    M = [i for i in range(1, int(generation))]\n",
    "    using_H = H[idx]\n",
    "    for using_M in M:\n",
    "        print(f'now using_generationH : {generation}, using_M: {using_M}')\n",
    "        individuals = all_individuals[(all_individuals['generations']==generation) & (all_individuals['generation']<=using_M) & (all_individuals['approach'] == 'incremental-data_lab28_special_utilization_model12.pth')]\n",
    "        quality_indicators_df = compute_quality_indicators(df=individuals, quality_indicator=quality_indicators, using_H=using_H, using_M=using_M)\n",
    "        data = pd.concat((data, quality_indicators_df))\n",
    "\n",
    "quality_indicators_df = data\n",
    "quality_indicators_df.to_csv(os.path.join(base_dir, 're_eval_quality_indicators.csv'), index=False)\n",
    "quality_indicators_df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done on all the individuals that were evaluated in an experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or on all individuals that belong to the final result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical comparison among the indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality_indicators_df = pd.DataFrame()\n",
    "for generation in np.array([\"20\"]):\n",
    "    quality_indicators_df = compute_quality_indicators(df=reconciled_results[reconciled_results.generations==generation], quality_indicators=quality_indicators)\n",
    "    quality_indicators_df['generations'] = generation \n",
    "    all_quality_indicators_df = all_quality_indicators_df.append(quality_indicators_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality_indicators_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the quality indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality_indicators_df = pd.read_csv(os.path.join(base_dir, 'quality_indicators.csv'))\n",
    "all_quality_indicators_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from a12 import a12\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = np.array([20])\n",
    "approaches = list(all_quality_indicators_df['approach'].unique())\n",
    "indicators = ['IGD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_comparison_data = []\n",
    "for indicator in indicators: \n",
    "    for generation_1, approach_1 in product(generations, approaches):\n",
    "        for generation_2, approach_2 in product(generations, approaches):\n",
    "            if (generation_1 == generation_2) and (approach_1 != approach_2) and approaches.index(approach_2) > approaches.index(approach_1): \n",
    "                indicator_1 = all_quality_indicators_df[(all_quality_indicators_df.approach==approach_1)][indicator]\n",
    "                indicator_2 = all_quality_indicators_df[(all_quality_indicators_df.approach==approach_2)][indicator]\n",
    "                try:\n",
    "                    a12_stats = a12(indicator_1, indicator_2)\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "                try:\n",
    "                    utest_stats, utest_pvalue = mannwhitneyu(indicator_1, indicator_2)\n",
    "                except ValueError:\n",
    "                    utest_stats, utest_pvalue = np.nan, np.nan\n",
    "                better = (\"SAME\" if utest_pvalue > 0.05 else ((approach_1 if a12_stats > 0.5 else approach_2) if indicator == \"HV\" else (approach_1 if a12_stats < 0.5 else approach_2)))\n",
    "                statistical_comparison_data.append({'max_generation_1' : generation_1, 'approach_1': approach_1, \n",
    "                                                   'max_generation_2' : generation_2, 'approach_2': approach_2,\n",
    "                                                    'indicator': indicator, \n",
    "                                                   'a12_stats': a12_stats, 'utest_stats': utest_stats, 'utest_pvalue': utest_pvalue, 'better': better})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(statistical_comparison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df[(stats_df.utest_pvalue < 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df[(stats_df.indicator == 'IGD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.to_csv(os.path.join(base_dir, 'A12.csv'),index=False)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_df_IGD = stats_df[(stats_df.utest_pvalue < 0.05)&(stats_df.indicator == 'IGD')]\n",
    "\n",
    "conditions = [(stats_df_IGD.better==\"SAME\"),\n",
    "            ((stats_df_IGD.a12_stats>0.5)&(stats_df_IGD.a12_stats<0.556)),\n",
    "           ((stats_df_IGD.a12_stats>=0.556)&(stats_df_IGD.a12_stats<0.638)),\n",
    "          ((stats_df_IGD.a12_stats>=0.638)&(stats_df_IGD.a12_stats<0.714)),\n",
    "          ((stats_df_IGD.a12_stats>=0.714)),\n",
    "          ((stats_df_IGD.a12_stats>0.494)&(stats_df_IGD.a12_stats<0.5)),\n",
    "          ((stats_df_IGD.a12_stats>0.362)&(stats_df_IGD.a12_stats<=0.494)),\n",
    "          ((stats_df_IGD.a12_stats>0.286)&(stats_df_IGD.a12_stats<=0.362)),\n",
    "          ((stats_df_IGD.a12_stats<=0.286))]\n",
    "choices = [\"same\", \"worseNegl\", \"worseSmall\", \"worseMedium\", \"worseLarge\", \"betterNegl\", \"betterSmall\", \"betterMedium\", \"betterLarge\"]\n",
    "stats_df_IGD['A12cat'] = np.select(conditions, choices, \"ERROR!\")\n",
    "stats_df_IGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the ending time because the variables are start time and how many hours will work.\n",
    "for i in range(10):\n",
    "    all_results[f'robot_{i}_end'] = all_results[f'robot_{i}_start'] + all_results[f'robot_{i}_end'] \n",
    "    all_results[f'robot_{i}_end'] = all_results[f'robot_{i}_end'].apply(lambda x: min(x, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
